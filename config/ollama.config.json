{
  "api": {
    "host": "0.0.0.0",
    "port": 11434
  },
  "gpu": {
    "enabled": false,
    "vendor": "nvidia"
  },
  "storage": {
    "path": "./llm-data"
  },
  "models": [
    "llama3:8b"
  ],
  "pullOnStart": true,
  "env": {
    "OLLAMA_NUM_CTX": 4096
  }
}
